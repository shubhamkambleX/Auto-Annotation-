{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy1HWB+CT+j1nxMWA1pE0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamkambleX/Auto-Annotation-/blob/main/Auto_Annotation_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0orX692Qx90",
        "outputId": "f6cfe28e-58f1-45a1-c362-567da805254a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from PIL import Image, ImageDraw"
      ],
      "metadata": {
        "id": "3zDhfdh8Q6y-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define a function for image annotation\n",
        "def annotate_image(image_path, output_path='annotated_images', confidence_threshold=0.5):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Process each image in the directory\n",
        "    for filename in os.listdir(image_path):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Load the image\n",
        "            img_path = os.path.join(image_path, filename)\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            # Preprocess the image\n",
        "            transform = T.Compose([T.ToTensor()])\n",
        "            input_img = transform(img).unsqueeze(0)\n",
        "\n",
        "            # Perform inference\n",
        "            with torch.no_grad():\n",
        "                prediction = model(input_img)\n",
        "\n",
        "            # Draw bounding boxes on the image\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "            scores = prediction[0]['scores'].cpu().numpy()\n",
        "\n",
        "            # Create a list to store coordinates\n",
        "            coordinates = []\n",
        "\n",
        "            for box, score in zip(boxes, scores):\n",
        "                if score > confidence_threshold:\n",
        "                    draw.rectangle(box, outline=\"red\", width=3)\n",
        "                    coordinates.append(box.tolist())\n",
        "\n",
        "            # Save annotated image\n",
        "            output_img_path = os.path.join(output_path, f'annotated_{filename}')\n",
        "            img.save(output_img_path)\n",
        "\n",
        "            # Save coordinates to a text file\n",
        "            output_txt_path = os.path.join(output_path, f'coordinates_{filename}.txt')\n",
        "            with open(output_txt_path, 'w') as f:\n",
        "                for coord in coordinates:\n",
        "                    f.write(','.join(map(str, coord)) + '\\n')\n",
        "\n",
        "# Test the annotation function on a directory of images\n",
        "annotate_image('/content/input_data', output_path='/content/output_data', confidence_threshold=0.5)\n"
      ],
      "metadata": {
        "id": "PBOfFr8LRAYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from PIL import Image, ImageDraw\n",
        "# import torch\n",
        "# from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "# from torchvision.transforms import functional as T\n",
        "# torchvision.transforms\n",
        "\n",
        "# Load pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define a function for image annotation\n",
        "def annotate_image(image_path, output_path='annotated_images', confidence_threshold=0.5):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Process each image in the directory\n",
        "    for filename in os.listdir(image_path):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Load the image\n",
        "            img_path = os.path.join(image_path, filename)\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            # Preprocess the image\n",
        "            transform = T.Compose([T.ToTensor()])\n",
        "            input_img = transform(img).unsqueeze(0)\n",
        "\n",
        "            # Perform inference\n",
        "            with torch.no_grad():\n",
        "                prediction = model(input_img)\n",
        "\n",
        "            # Draw bounding boxes on the image\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "            scores = prediction[0]['scores'].cpu().numpy()\n",
        "            labels = prediction[0]['labels'].cpu().numpy()\n",
        "\n",
        "            # Create a list to store coordinates and labels\n",
        "            annotations = []\n",
        "\n",
        "            for box, score, label in zip(boxes, scores, labels):\n",
        "                if score > confidence_threshold:\n",
        "                    draw.rectangle(box, outline=\"red\", width=3)\n",
        "                    coordinates = box.tolist()\n",
        "                    label_info = {'label': label, 'coordinates': coordinates}\n",
        "                    annotations.append(label_info)\n",
        "\n",
        "            # Save annotated image\n",
        "            output_img_path = os.path.join(output_path, f'annotated_{filename}')\n",
        "            img.save(output_img_path)\n",
        "\n",
        "            # Save coordinates and labels to a text file\n",
        "            output_txt_path = os.path.join(output_path, f'annotations_{filename}.txt')\n",
        "            with open(output_txt_path, 'w') as f:\n",
        "                for annotation in annotations:\n",
        "                    label_str = f\"label: {annotation['label']}\"\n",
        "                    coord_str = f\"coordinates: {','.join(map(str, annotation['coordinates']))}\"\n",
        "                    f.write(f\"{label_str}, {coord_str}\\n\")\n",
        "\n",
        "# Test the annotation function on a directory of images\n",
        "annotate_image('/content/input_data', output_path='/content/output_data', confidence_threshold=0.5)\n"
      ],
      "metadata": {
        "id": "j7nZa4j-x1ZZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from PIL import Image, ImageDraw\n",
        "# import torch\n",
        "# from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "# from torchvision.transforms import functional as T\n",
        "\n",
        "# Load pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define a function for image annotation\n",
        "def annotate_image(image_path, output_path='annotated_images', confidence_threshold=0.5,dynamic_val = [0,1,2]):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Process each image in the directory\n",
        "    for filename in os.listdir(image_path):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Load the image\n",
        "            img_path = os.path.join(image_path, filename)\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            # Preprocess the image\n",
        "            transform = T.Compose([T.ToTensor()])\n",
        "            input_img = transform(img).unsqueeze(0)\n",
        "\n",
        "            # Perform inference\n",
        "            with torch.no_grad():\n",
        "                prediction = model(input_img)\n",
        "\n",
        "            # Extract bounding boxes, scores, and labels\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "            scores = prediction[0]['scores'].cpu().numpy()\n",
        "            labels = prediction[0]['labels'].cpu().numpy()\n",
        "\n",
        "            # Create a list to store annotations\n",
        "            annotations = []\n",
        "\n",
        "            for box, score, label in zip(boxes, scores, labels):\n",
        "                if score > confidence_threshold:\n",
        "                    draw.rectangle(box, outline=\"red\", width=3)\n",
        "                    # Append label and coordinates to the list\n",
        "                    lab_name = dynamic_val[label] if dynamic_val and label < len(dynamic_val) else 0\n",
        "                    annotation_str = f\"{lab_name} {' '.join(map(str, box.tolist()))}\"\n",
        "                    annotations.append(annotation_str)\n",
        "\n",
        "            # Save annotated image\n",
        "            output_img_path = os.path.join(output_path, f'annotated_{filename}')\n",
        "            img.save(output_img_path)\n",
        "\n",
        "            # Save annotations to a text file\n",
        "            output_txt_path = os.path.join(output_path, f'annotations_{filename}.txt')\n",
        "            with open(output_txt_path, 'w') as f:\n",
        "                for annotation in annotations:\n",
        "                    f.write(annotation + '\\n')\n",
        "\n",
        "# Test the annotation function on a directory of images\n",
        "annotate_image('/content/input_data', output_path='/content/output_data', confidence_threshold=0.5)\n"
      ],
      "metadata": {
        "id": "BardJAQEyH2D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7abx9OF24aY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}